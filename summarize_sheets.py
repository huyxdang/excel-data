"""
Summarize Sheets using Claude API

Analyzes each extracted CSV sheet using Claude Sonnet 4.5 and generates
structured markdown summaries suitable for BRD synthesis.

Usage:
    python summarize_sheets.py <sheets_dir> <output_dir> [--api-key KEY]

Example:
    python summarize_sheets.py output/sheets output/summaries
    python summarize_sheets.py output/sheets output/summaries --api-key sk-ant-...
    
Environment:
    ANTHROPIC_API_KEY - API key for Claude (loaded from .env file or environment)
    
.env file format:
    ANTHROPIC_API_KEY=sk-ant-...
    
Output:
    output/summaries/
    ‚îú‚îÄ‚îÄ 0.md
    ‚îú‚îÄ‚îÄ 1.md
    ‚îú‚îÄ‚îÄ 5.md
    ‚îú‚îÄ‚îÄ 5.1.1a.md
    ‚îî‚îÄ‚îÄ ...
    output/summaries/_index.md (summary index)
"""

import sys
import os
import csv
import glob
import argparse
from pathlib import Path
from anthropic import Anthropic
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()


SUMMARIZATION_PROMPT = """ƒê·ªçc sheet n√†y t·ª´ t√†i li·ªáu Y√™u c·∫ßu Nghi·ªáp v·ª• (BRD) v√† ph√¢n t√≠ch n·ªôi dung.

T√™n sheet: {sheet_name}
N·ªôi dung sheet (ƒë·ªãnh d·∫°ng CSV):
{content}

Vui l√≤ng ƒë∆∞a ra:

1. **Lo·∫°i sheet**: Ph√¢n lo·∫°i l√† m·ªôt trong c√°c lo·∫°i: t·ªïng-quan/quy-tr√¨nh/giao-di·ªán/ƒë·∫∑c-t·∫£/m√¥-h√¨nh-d·ªØ-li·ªáu/kh√°c

2. **M·ª©c ƒë·ªô chi ti·∫øt**: Ph√¢n lo·∫°i l√† m·ªôt trong hai lo·∫°i:
   - `chi-ti·∫øt-cao`: Sheet ch·ª©a nhi·ªÅu th√¥ng s·ªë k·ªπ thu·∫≠t, s·ªë li·ªáu c·ª• th·ªÉ, validation rules, field specifications, ho·∫∑c data mapping ‚Üí C·∫¶N GI·ªÆ NGUY√äN D·∫†NG B·∫¢NG
   - `t·ªïng-quan`: Sheet ch·ª©a m√¥ t·∫£ quy tr√¨nh, lu·ªìng c√¥ng vi·ªác, ho·∫∑c th√¥ng tin high-level ‚Üí C√ì TH·ªÇ CHUY·ªÇN TH√ÄNH PROSE/SECTIONS

3. **Ch·ªß ƒë·ªÅ/ti√™u ƒë·ªÅ ch√≠nh**: Ch·ªß ƒë·ªÅ ho·∫∑c m·ª•c ƒë√≠ch ch√≠nh c·ªßa sheet n√†y l√† g√¨?

4. **T√≥m t·∫Øt th√¥ng tin ch√≠nh**: Cung c·∫•p 2-3 ƒëo·∫°n vƒÉn t√≥m t·∫Øt c√°c th√¥ng tin thi·∫øt y·∫øu, logic nghi·ªáp v·ª• v√† y√™u c·∫ßu trong sheet n√†y.

5. **C√°c b√™n li√™n quan/vai tr√≤ ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p**: Li·ªát k√™ c√°c c√° nh√¢n, nh√≥m, vai tr√≤ ho·∫∑c ph√≤ng ban ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p.

6. **C√°c y√™u c·∫ßu t√¨m th·∫•y**: Tr√≠ch xu·∫•t c√°c y√™u c·∫ßu, ƒë·∫∑c t·∫£ ho·∫∑c r√†ng bu·ªôc r√µ r√†ng (n·∫øu c√≥).

7. **C√°c sheet li√™n quan**: X√°c ƒë·ªãnh c√°c tham chi·∫øu ƒë·∫øn sheet kh√°c, t√†i li·ªáu ho·∫∑c h·ªá th·ªëng kh√°c.

8. **B·∫£ng c·∫ßn gi·ªØ nguy√™n** (CH·ªà khi m·ª©c ƒë·ªô chi ti·∫øt = `chi-ti·∫øt-cao`):
   N·∫øu sheet ch·ª©a b·∫£ng v·ªõi th√¥ng s·ªë k·ªπ thu·∫≠t quan tr·ªçng, h√£y chuy·ªÉn ƒë·ªïi sang ƒë·ªãnh d·∫°ng Markdown table v√† ƒë∆∞a v√†o ƒë√¢y.
   
   C√°c lo·∫°i b·∫£ng C·∫¶N gi·ªØ nguy√™n:
   - B·∫£ng field specifications (t√™n tr∆∞·ªùng, ki·ªÉu d·ªØ li·ªáu, ƒë·ªô d√†i, b·∫Øt bu·ªôc/kh√¥ng)
   - B·∫£ng validation rules
   - B·∫£ng status/state transitions
   - B·∫£ng data mapping (source ‚Üí target)
   - B·∫£ng API specifications
   - B·∫£ng error codes
   - B·∫£ng permission/role matrix
   
   ƒê·ªãnh d·∫°ng Markdown table:
   ```markdown
   | T√™n tr∆∞·ªùng | Ki·ªÉu d·ªØ li·ªáu | ƒê·ªô d√†i | B·∫Øt bu·ªôc | M√¥ t·∫£ |
   |------------|--------------|--------|----------|-------|
   | ma_yeu_cau | VARCHAR      | 50     | C√≥       | M√£ y√™u c·∫ßu theo format NK.YY.xxxx |
   ```

Tr√¨nh b√†y ph√¢n t√≠ch c·ªßa b·∫°n d∆∞·ªõi d·∫°ng markdown ng√¥n ng·ªØ t·ª± nhi√™n (KH√îNG ph·∫£i JSON). Ng·∫Øn g·ªçn nh∆∞ng ƒë·∫ßy ƒë·ªß."""


def load_csv_content(csv_path: str, max_rows: int = 500) -> tuple[str, int]:
    """
    Load CSV content as text, limited to max_rows.
    
    Returns:
        (content_text, total_row_count)
    """
    rows = []
    total_rows = 0
    
    try:
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            for i, row in enumerate(reader):
                total_rows += 1
                if i < max_rows:
                    rows.append(','.join(row))
                    
        content = '\n'.join(rows)
        
        if total_rows > max_rows:
            content += f"\n\n... ({total_rows - max_rows} more rows truncated)"
            
        return content, total_rows
        
    except Exception as e:
        print(f"Error reading {csv_path}: {e}")
        return "", 0


def summarize_sheet(client: Anthropic, sheet_name: str, csv_path: str, max_tokens: int = 2000) -> str:
    """
    Use Claude API to summarize a single sheet.
    
    Returns:
        Markdown summary text
    """
    content, row_count = load_csv_content(csv_path)
    
    if not content:
        return f"# {sheet_name}\n\n*Error: Could not read sheet content*"
    
    prompt = SUMMARIZATION_PROMPT.format(
        sheet_name=sheet_name,
        content=content
    )
    
    try:
        message = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=max_tokens,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        
        summary = message.content[0].text
        
        # Add metadata footer
        summary += f"\n\n---\n*Source: {sheet_name}.csv | Rows: {row_count} | Generated by Claude Sonnet 4.5*\n"
        
        return summary
        
    except Exception as e:
        error_msg = f"# {sheet_name}\n\n*Error generating summary: {e}*"
        return error_msg


def get_sheet_name_from_filename(filename: str) -> str:
    """
    Extract sheet name from CSV filename.
    
    Examples:
        '5.1.1a.csv' -> '5.1.1a'
        'Status.csv' -> 'Status'
    """
    return os.path.splitext(os.path.basename(filename))[0]


def summarize_all_sheets(sheets_dir: str, output_dir: str, api_key: str = None) -> dict:
    """
    Summarize all CSV sheets in the directory.
    
    Args:
        sheets_dir: Directory containing CSV files
        output_dir: Directory to save markdown summaries
        api_key: Optional API key (uses env var if not provided)
        
    Returns:
        Dictionary with summarization results
    """
    # Initialize Anthropic client
    client = Anthropic(api_key=api_key) if api_key else Anthropic()
    
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    # Find all CSV files
    csv_files = sorted(glob.glob(os.path.join(sheets_dir, "*.csv")))
    
    if not csv_files:
        print(f"No CSV files found in {sheets_dir}")
        return {'success': [], 'failed': []}
    
    print(f"Found {len(csv_files)} CSV files")
    print("-" * 60)
    
    results = {
        'success': [],
        'failed': [],
        'summaries': {}
    }
    
    for i, csv_path in enumerate(csv_files):
        sheet_name = get_sheet_name_from_filename(csv_path)
        output_md = os.path.join(output_dir, f"{sheet_name}.md")
        
        print(f"[{i+1}/{len(csv_files)}] Summarizing '{sheet_name}'...", end=" ", flush=True)
        
        try:
            summary = summarize_sheet(client, sheet_name, csv_path)
            
            # Write summary to file
            with open(output_md, 'w', encoding='utf-8') as f:
                f.write(summary)
            
            file_size = os.path.getsize(output_md)
            print(f"‚úì ({file_size:,} bytes)")
            
            results['success'].append(sheet_name)
            results['summaries'][sheet_name] = {
                'csv_path': csv_path,
                'md_path': output_md,
                'size': file_size
            }
            
        except Exception as e:
            print(f"‚úó {e}")
            results['failed'].append(sheet_name)
    
    # Create index file
    create_index(results, output_dir)
    
    return results


def create_index(results: dict, output_dir: str):
    """Create an index markdown file listing all summaries."""
    index_path = os.path.join(output_dir, "_index.md")
    
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write("# Sheet Summaries Index\n\n")
        f.write(f"Total sheets: {len(results['success']) + len(results['failed'])}\n")
        f.write(f"- Successfully summarized: {len(results['success'])}\n")
        f.write(f"- Failed: {len(results['failed'])}\n\n")
        
        if results['success']:
            f.write("## Summaries\n\n")
            for sheet_name in sorted(results['success']):
                info = results['summaries'][sheet_name]
                f.write(f"- [{sheet_name}](./{sheet_name}.md) ({info['size']:,} bytes)\n")
        
        if results['failed']:
            f.write("\n## Failed\n\n")
            for sheet_name in results['failed']:
                f.write(f"- {sheet_name}\n")
    
    print(f"\nüìÑ Index created: {index_path}")


def main():
    parser = argparse.ArgumentParser(
        description="Summarize Excel sheets using Claude API",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    parser.add_argument(
        'sheets_dir',
        help='Directory containing CSV sheet files'
    )
    
    parser.add_argument(
        'output_dir',
        help='Directory to save markdown summaries'
    )
    
    parser.add_argument(
        '--api-key',
        help='Anthropic API key (uses .env file or ANTHROPIC_API_KEY env var if not provided)'
    )
    
    args = parser.parse_args()
    
    if not os.path.exists(args.sheets_dir):
        print(f"Error: Sheets directory not found: {args.sheets_dir}")
        sys.exit(1)
    
    # Check for API key
    api_key = args.api_key or os.environ.get('ANTHROPIC_API_KEY')
    if not api_key:
        print("Error: No API key provided.")
        print("Please either:")
        print("  1. Create a .env file with: ANTHROPIC_API_KEY=sk-ant-...")
        print("  2. Set ANTHROPIC_API_KEY environment variable")
        print("  3. Use --api-key argument")
        sys.exit(1)
    
    print(f"Sheets dir: {args.sheets_dir}")
    print(f"Output dir: {args.output_dir}")
    print(f"Model: Claude Sonnet 4.5")
    print("=" * 60)
    
    results = summarize_all_sheets(args.sheets_dir, args.output_dir, api_key)
    
    print("=" * 60)
    print(f"‚úÖ Summarization complete")
    print(f"   Success: {len(results['success'])} sheets")
    print(f"   Failed:  {len(results['failed'])} sheets")
    print(f"   Output:  {args.output_dir}/")
    
    if results['failed']:
        print(f"\n‚ö†Ô∏è  Failed sheets: {results['failed']}")


if __name__ == "__main__":
    main()